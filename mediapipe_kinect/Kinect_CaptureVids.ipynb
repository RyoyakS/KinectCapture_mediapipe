{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS Kinect Video Capture Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  22.637730071021576\n",
      "Video output finished!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pykinect_azure as pykinect\n",
    "from pykinect_azure.k4a import calibration\n",
    "from pykinect_azure.k4a import _k4a\n",
    "import time\n",
    "\n",
    "# file name setting\n",
    "Date=\"1117\"\n",
    "TrackName = [\"test\",\"Arlequin\", \"Eusebins\", \"Floresla\", \"Pierrot\", \"Valse Nobles\",\"Promenade\"]\n",
    "VideoType = [\"\",\"_above\", \"_above2\",\"_short\"]\n",
    "file_name = TrackName[6]+VideoType[2]\n",
    "\n",
    "video_folder=\"./sample/videos/\"+Date+\"/\"\n",
    "os.makedirs(video_folder, exist_ok=True)\n",
    "json_folder=\"./sample/json/\"+Date+\"/\"\n",
    "os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "json_file = json_folder+file_name+\".json\"\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the library, if the library is not found, add the library path as an argument\n",
    "pykinect.initialize_libraries(track_body=True)\n",
    "\n",
    "# Modify camera configuration\n",
    "device_config = pykinect.default_configuration\n",
    "device_config.color_resolution = pykinect.K4A_COLOR_RESOLUTION_1080P\n",
    "device_config.color_format = pykinect.K4A_IMAGE_FORMAT_COLOR_BGRA32\n",
    "device_config.camera_fps = pykinect.K4A_FRAMES_PER_SECOND_30\n",
    "device_config.depth_mode = pykinect.K4A_DEPTH_MODE_WFOV_2X2BINNED\n",
    "device_config.synchronized_images_only =True\n",
    "# print(device_config)\n",
    "\n",
    "\n",
    "# output video setting\n",
    "fps =30.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # 'H264' is the codec for MP4\n",
    "out＿RGB = cv2.VideoWriter(video_folder+file_name+\"_RGB\"+\".mp4\", fourcc, fps, (1920, 1080))  # Adjust the resolution as needed\n",
    "out_Ndepth = cv2.VideoWriter(video_folder+file_name+\"_normalized_depth\"+\".mp4\", fourcc, fps, (1920, 1080))  # Adjust the resolution as needed\n",
    "\n",
    "# Start device\n",
    "device = pykinect.start_device(config=device_config)\n",
    "\n",
    "# Start body tracker\n",
    "bodyTracker = pykinect.start_body_tracker()\n",
    "# clamp 調遠方的點雲 rescaling 近處的\n",
    "# Set the desired depth range for visualization\n",
    "min_depth = 600   # Adjust this value based on your specific scenario\n",
    "max_depth = 1200 # Adjust this value based on your specific scenario\n",
    "\n",
    "# 問題不是FOV 而是distortion，depth不能直接拿來用\n",
    "# 先去照能照到手的問題\n",
    "# window_size = (1280, 720)\n",
    "frame_idx = 0\n",
    "t = time.time()\n",
    "try:\n",
    "    while True:\n",
    "        # Get capture\n",
    "        capture = device.update()\n",
    "        # Get body tracker frame\n",
    "        # body_frame = bodyTracker.update()\n",
    "        # Get the color image\n",
    "        ret_rgb, img_RGB = capture.get_color_image()\n",
    "        #不會distortion 的 depth photo\n",
    "        # ret_depth, img_depth = capture.get_transformed_colored_depth_image()\n",
    "        ret_depth, img_depth = capture.get_transformed_depth_image()\n",
    "        # ret_color, body_image_color = body_frame.get_segmentation_image()\n",
    "        \n",
    "        if not ret_rgb or not ret_depth:\n",
    "            continue\n",
    "        \n",
    "        normalized_depth = np.clip(img_depth, min_depth, max_depth)\n",
    "        normalized_depth = (normalized_depth - min_depth) / (max_depth - min_depth) * 255\n",
    "        normalized_depth = normalized_depth.astype(np.uint8)\n",
    "        # _img_depth= _img_depth.astype(np.uint8)\n",
    "        # ret_ir, img_ir = capture.get_ir_image()\n",
    "\n",
    "        \n",
    "        # Display the color image\n",
    "        cv2.imshow('MIS Kinect View RGB', img_RGB)\n",
    "        # cv2.resizeWindow('MIS Kinect View RGB', *window_size)\n",
    "        # cv2.imshow('MIS Kinect View Depth', img_depth)\n",
    "        cv2.imshow('MIS Kinect View Normalized Depth', normalized_depth)\n",
    "    \n",
    "        # cv2.imshow('MIS Kinect View IR', img_ir)\n",
    "        # video output\n",
    "        out＿RGB.write(img_RGB)\n",
    "        out_Ndepth.write(normalized_depth)\n",
    "        # wait=cv2.waitKey(1000)\n",
    "        # Press q key to stop\n",
    "        key = cv2.waitKey(1)\n",
    "        frame_idx+=1\n",
    "        # print(frame_idx)\n",
    "        if key == ord('q') or key == 27:  # Check for 'q' key or ESC key\n",
    "            break\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     # Release the resources\n",
    "#     print(\"FPS: \", frame_idx/(time.time()-t))\n",
    "#     cv2.destroyAllWindows()\n",
    "#     device.close()\n",
    "#     out＿RGB.release()\n",
    "#     out_Ndepth.release()\n",
    "finally:\n",
    "    # Release the resources\n",
    "    print(\"FPS: \", frame_idx/(time.time()-t))\n",
    "    cv2.destroyAllWindows()\n",
    "    device.close()\n",
    "    out＿RGB.release()\n",
    "    out_Ndepth.release()\n",
    "\n",
    "print(\"Video output finished!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pykinect_azure as pykinect\n",
    "# from pykinect_azure.k4a import calibration\n",
    "# from pykinect_azure.k4a import _k4a\n",
    "# import time\n",
    "\n",
    "# # file name setting\n",
    "# Date=\"1116\"\n",
    "# TrackName = [\"test\",\"Arlequin\", \"Eusebins\", \"Floresla\", \"Pierrot\", \"Valse Nobles\"]\n",
    "# VideoType = [\"\",\"_above\", \"_side\",\"_short\"]\n",
    "# file_name = TrackName[0]+VideoType[0]\n",
    "\n",
    "# video_folder=\"./sample/videos/\"+Date+\"/\"\n",
    "# os.makedirs(video_folder, exist_ok=True)\n",
    "# json_folder=\"./sample/json/\"+Date+\"/\"\n",
    "# os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "# json_file = json_folder+file_name+\".json\"\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize the library, if the library is not found, add the library path as an argument\n",
    "# pykinect.initialize_libraries(track_body=True)\n",
    "\n",
    "# # Modify camera configuration\n",
    "# device_config = pykinect.default_configuration\n",
    "# device_config.color_resolution = pykinect.K4A_COLOR_RESOLUTION_1080P\n",
    "# device_config.color_format = pykinect.K4A_IMAGE_FORMAT_COLOR_BGRA32\n",
    "# device_config.camera_fps = pykinect.K4A_FRAMES_PER_SECOND_30\n",
    "# device_config.depth_mode = pykinect.K4A_DEPTH_MODE_WFOV_2X2BINNED\n",
    "# device_config.synchronized_images_only =True\n",
    "# print(device_config)\n",
    "\n",
    "\n",
    "# # output video setting\n",
    "# fps =30.0\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'H264')  # 'H264' is the codec for MP4\n",
    "# out＿RGB = cv2.VideoWriter(video_folder+file_name+\"_RGB\"+\".mp4\"\n",
    "#                           , fourcc, fps, (1920, 1080))  # Adjust the resolution as needed\n",
    "# out_Ndepth = cv2.VideoWriter(video_folder+file_name+\"_normalized_depth\"+\".mp4\"\n",
    "#                             , fourcc, fps, (1920, 1080))  # Adjust the resolution as needed\n",
    "\n",
    "# # Start device\n",
    "# device = pykinect.start_device(config=device_config)\n",
    "\n",
    "# # Start body tracker\n",
    "# bodyTracker = pykinect.start_body_tracker()\n",
    "# # clamp 調遠方的點雲 rescaling 近處的\n",
    "# # Set the desired depth range for visualization\n",
    "# min_depth = 900   # Adjust this value based on your specific scenario\n",
    "# max_depth = 1200 # Adjust this value based on your specific scenario\n",
    "\n",
    "# # 問題不是FOV 而是distortion，depth不能直接拿來用\n",
    "# # 先去照能照到手的問題\n",
    "# # window_size = (1280, 720)\n",
    "# frame_idx = 0\n",
    "# t = time.time()\n",
    "# try: \n",
    "#     while True:\n",
    "#         # Get capture\n",
    "#         capture = device.update()\n",
    "#         # Get body tracker frame\n",
    "#         # body_frame = bodyTracker.update()\n",
    "#         # Get the color image\n",
    "#         ret_rgb, img_RGB = capture.get_color_image()\n",
    "#         #不會distortion 的 depth photo\n",
    "#         # ret_depth, img_depth = capture.get_transformed_colored_depth_image()\n",
    "#         ret_depth, img_depth = capture.get_transformed_depth_image()\n",
    "#         # ret_color, body_image_color = body_frame.get_segmentation_image()\n",
    "        \n",
    "#         # if not ret_rgb or not ret_depth:\n",
    "#         #     continue\n",
    "        \n",
    "#         normalized_depth = np.clip(img_depth, min_depth, max_depth)\n",
    "#         normalized_depth = (normalized_depth - min_depth) / (max_depth - min_depth) * 255\n",
    "#         normalized_depth = normalized_depth.astype(np.uint8)\n",
    "#         # _img_depth= _img_depth.astype(np.uint8)\n",
    "#         # ret_ir, img_ir = capture.get_ir_image()\n",
    "\n",
    "        \n",
    "#         # Display the color image\n",
    "#         cv2.imshow('MIS Kinect View RGB', img_RGB)\n",
    "#         # cv2.resizeWindow('MIS Kinect View RGB', *window_size)\n",
    "#         # cv2.imshow('MIS Kinect View Depth', img_depth)\n",
    "#         cv2.imshow('MIS Kinect View Normalized Depth', normalized_depth)\n",
    "        \n",
    "#         # cv2.imshow('MIS Kinect View IR', img_ir)\n",
    "#         # video output\n",
    "#         # out＿RGB.write(img_RGB)\n",
    "#         # out_Ndepth.write(normalized_depth)\n",
    "#         # wait=cv2.waitKey(1000)\n",
    "#         # Press q key to stop\n",
    "#         # key = cv2.waitKey(1)\n",
    "#         frame_idx+=1\n",
    "#         print(frame_idx)\n",
    "\n",
    "#         # time\n",
    "#         # if key == ord('q') or key == 27:  # Check for 'q' key or ESC key\n",
    "#         #     break\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Video output finished!\")\n",
    "#     print(\"FPS: \", frame_idx/(time.time()-t))\n",
    "#     cv2.destroyAllWindows()\n",
    "#     device.close()\n",
    "#     out＿RGB.release()\n",
    "#     out_Ndepth.release()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows()\n",
    "# device.close()\n",
    "# out＿RGB.release()\n",
    "# out_Ndepth.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
